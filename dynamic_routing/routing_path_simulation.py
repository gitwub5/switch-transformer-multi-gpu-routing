import os
import joblib
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import networkx as nx
from collections import defaultdict

# ============================
# ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
# ============================
def load_all_models(model_base_dir):
    models = {}

    for layer_type in ["encoder", "decoder"]:
        type_path = os.path.join(model_base_dir, layer_type)
        if not os.path.exists(type_path):
            continue

        for fname in os.listdir(type_path):
            if fname.endswith(".joblib"):
                layer_index = int(fname.replace("layer_", "").replace(".joblib", ""))
                model = joblib.load(os.path.join(type_path, fname))
                models[(layer_type, layer_index)] = model

    return models

# ============================
# ë¼ìš°íŒ… ê²½ë¡œ ì‹œë®¬ë ˆì´ì…˜
# ============================
def simulate_routing_path(token_feature: dict, models: dict):
    """
    ë‹¨ì¼ í† í°ì˜ ì „ì²´ ë¼ìš°íŒ… ê²½ë¡œë¥¼ ì‹œë®¬ë ˆì´ì…˜
    
    Returns:
        list: [(layer_index, expert_id, gpu_id, latency), ...]
    """
    path = []
    current_layer = token_feature["layer_index"]
    current_type = "encoder" if token_feature["layer_type_encoded"] == 0 else "decoder"
    
    # ë¼ìš°íŒ… ê°€ëŠ¥í•œ layer ì •ì˜
    ROUTING_LAYERS = {
        "encoder": [1, 3, 5, 7, 9, 11],
        "decoder": [1, 3, 5, 7, 9, 11]
    }
    
    # í˜„ì¬ layerê°€ ë¼ìš°íŒ… ê°€ëŠ¥í•œ layerì¸ì§€ í™•ì¸
    if current_layer not in ROUTING_LAYERS[current_type]:
        return path
    
    # í˜„ì¬ layerì˜ ëª¨ë¸ ê°€ì ¸ì˜¤ê¸°
    model_key = (current_type, current_layer)
    if model_key not in models:
        return path
    
    model = models[model_key]
    
    # ëœë¤í•˜ê²Œ expert ì„ íƒ
    expert_id = np.random.randint(0, 8)  # 0ë¶€í„° 7ê¹Œì§€ ëœë¤ ì„ íƒ
    gpu_id = np.random.randint(0, 2)  # 0 ë˜ëŠ” 1 ëœë¤ ì„ íƒ
    
    # íŠ¹ì„± ë²¡í„° ìƒì„± (token_id ì œì™¸)
    feature_vec = [
        token_feature["router_entropy"],
        token_feature["router_score"],
        token_feature["layer_token_count"],
        expert_id,
        gpu_id
    ]
    
    pred_latency = model.predict([feature_vec])[0]
    pred_latency = max(0.0, pred_latency)
    
    path.append((current_layer, expert_id, gpu_id, pred_latency))
    
    return path

# ============================
# ê²½ë¡œ ì‹œê°í™”
# ============================
def visualize_routing_path(path, output_path=None):
    """
    ë¼ìš°íŒ… ê²½ë¡œë¥¼ ì‹œê°í™”
    
    Args:
        path: [(layer_index, expert_id, gpu_id, latency), ...]
        output_path: ì €ì¥í•  íŒŒì¼ ê²½ë¡œ
    """
    plt.figure(figsize=(15, 8))
    
    # Encoderì™€ Decoder ê²½ë¡œ ë¶„ë¦¬
    encoder_path = path[:6]  # ì²˜ìŒ 6ê°œëŠ” encoder
    decoder_path = path[6:]  # ë‚˜ë¨¸ì§€ëŠ” decoder
    
    # ë…¸ë“œ ìœ„ì¹˜ ê³„ì‚°
    def get_node_positions(path, start_x, y_offset=0):
        positions = {}
        for i, (layer, expert, gpu, _) in enumerate(path):
            x = start_x + i * 2
            y = y_offset
            positions[f"L{layer}_E{expert}_G{gpu}"] = (x, y)
        return positions
    
    # Encoderì™€ Decoder ë…¸ë“œ ìœ„ì¹˜ ê³„ì‚°
    encoder_pos = get_node_positions(encoder_path, 0, 1)
    decoder_pos = get_node_positions(decoder_path, 0, 0)
    pos = {**encoder_pos, **decoder_pos}
    
    # ê·¸ë˜í”„ ìƒì„±
    G = nx.DiGraph()
    
    # ë…¸ë“œ ì¶”ê°€
    for i, (layer, expert, gpu, latency) in enumerate(path):
        node_id = f"L{layer}_E{expert}_G{gpu}"
        is_encoder = i < 6
        G.add_node(node_id, 
                  layer=layer,
                  expert=expert,
                  gpu="1080Ti" if gpu == 0 else "A6000",
                  latency=f"{latency:.3f}ms",
                  type="Encoder" if is_encoder else "Decoder")
    
    # ì—£ì§€ ì¶”ê°€
    for i in range(len(path)-1):
        G.add_edge(f"L{path[i][0]}_E{path[i][1]}_G{path[i][2]}",
                  f"L{path[i+1][0]}_E{path[i+1][1]}_G{path[i+1][2]}")
    
    # ë…¸ë“œ ê·¸ë¦¬ê¸°
    encoder_nodes = [n for n in G.nodes() if G.nodes[n]['type'] == "Encoder"]
    decoder_nodes = [n for n in G.nodes() if G.nodes[n]['type'] == "Decoder"]
    
    nx.draw_networkx_nodes(G, pos, nodelist=encoder_nodes, 
                          node_color='lightblue', node_size=2000, alpha=0.7)
    nx.draw_networkx_nodes(G, pos, nodelist=decoder_nodes, 
                          node_color='lightgreen', node_size=2000, alpha=0.7)
    
    # ì—£ì§€ ê·¸ë¦¬ê¸°
    nx.draw_networkx_edges(G, pos, edge_color='gray', 
                          arrows=True, arrowsize=20)
    
    # ë ˆì´ë¸” ê·¸ë¦¬ê¸°
    labels = {node: f"{G.nodes[node]['layer']}\nExpert {G.nodes[node]['expert']}\n{G.nodes[node]['gpu']}\n{G.nodes[node]['latency']}"
              for node in G.nodes()}
    nx.draw_networkx_labels(G, pos, labels, font_size=8)
    
    # ì œëª©ê³¼ ë²”ë¡€ ì¶”ê°€
    plt.title("Token Routing Path", pad=20)
    plt.text(0.02, 0.98, "Encoder", transform=plt.gca().transAxes, 
             bbox=dict(facecolor='lightblue', alpha=0.5))
    plt.text(0.02, 0.02, "Decoder", transform=plt.gca().transAxes, 
             bbox=dict(facecolor='lightgreen', alpha=0.5))
    
    plt.axis('off')
    
    if output_path:
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
    plt.show()

# ============================
# ì „ì²´ ë¼ìš°íŒ… ê²½ë¡œ ì‹œë®¬ë ˆì´ì…˜ (ìˆœì°¨ ì—°ê²°)
# ============================
def simulate_full_routing_path(token_feature: dict, models: dict):
    """
    Encoder 1~11 â†’ Decoder 1~11ì„ ìˆœì°¨ì ìœ¼ë¡œ ë¼ìš°íŒ…í•˜ë©° ì „ì²´ ê²½ë¡œë¥¼ ë°˜í™˜
    """
    path = []
    token = token_feature.copy()
    encoder_layers = [1, 3, 5, 7, 9, 11]
    decoder_layers = [1, 3, 5, 7, 9, 11]

    # Encoder
    for layer in encoder_layers:
        token["layer_index"] = layer
        token["layer_type_encoded"] = 0
        step = simulate_routing_path(token, models)
        if step:
            path.extend(step)
    # Decoder
    for layer in decoder_layers:
        token["layer_index"] = layer
        token["layer_type_encoded"] = 1
        step = simulate_routing_path(token, models)
        if step:
            path.extend(step)
    return path

# ============================
# ì‹¤í–‰
# ============================
if __name__ == "__main__":
    MODEL_DIR = "models"
    OUTPUT_DIR = "results"
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    # ëª¨ë¸ ë¡œë“œ
    models = load_all_models(MODEL_DIR)
    
    # ì „ì²´ ê²½ë¡œ ì‹œë®¬ë ˆì´ì…˜ì„ ìœ„í•œ í† í°
    token = {
        "layer_index": 1,
        "router_entropy": 0.32,
        "router_score": 0.5,
        "layer_token_count": 128,
        "layer_type_encoded": 0,  # encoder
        "gpu_id_encoded": 0  # 1080Ti
    }
    
    # ì „ì²´ ê²½ë¡œ ì‹œë®¬ë ˆì´ì…˜ (ìˆœì°¨ ì—°ê²°)
    full_path = simulate_full_routing_path(token, models)
    
    # ê²°ê³¼ ì¶œë ¥
    print("\nğŸ”€ ì „ì²´ ë¼ìš°íŒ… ê²½ë¡œ:")
    encoder_layers = [1, 3, 5, 7, 9, 11]
    for i, (layer, expert, gpu, latency) in enumerate(full_path):
        layer_type = "Encoder" if i < len(encoder_layers) else "Decoder"
        print(f"  {layer_type} Layer {layer} -> Expert {expert} -> GPU {gpu} ({'1080Ti' if gpu == 0 else 'A6000'})")
        print(f"  ì˜ˆìƒ ì§€ì—°ì‹œê°„: {latency:.3f}ms")
    
    # ê²½ë¡œ ì‹œê°í™”
    visualize_routing_path(full_path, os.path.join(OUTPUT_DIR, "full_routing_path.png")) 