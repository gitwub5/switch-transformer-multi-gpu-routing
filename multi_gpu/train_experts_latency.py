import pandas as pd
import numpy as np
import os
import joblib
import matplotlib.pyplot as plt
from sklearn.linear_model import Ridge
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import GridSearchCV
from sklearn.svm import SVR
from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import Pipeline
import seaborn as sns

# ê²½ë¡œ ìƒì„±
for layer in ["encoder", "decoder"]:
    for gpu in ["1080Ti", "A6000"]:
        os.makedirs(f'{layer}/{gpu}', exist_ok=True)
        os.makedirs(f'results/{layer}/{gpu}', exist_ok=True)

# ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬
df = pd.read_csv("../outputs/merged_latency_comparison.csv")
df["layer_expert"] = df["layer_type"] + "_" + df["layer_index"].astype(str) + "_" + df["expert_id"].astype(str)
df["token_count_log"] = np.log1p(df["token_count"])

def remove_outliers_iqr(df, column):
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1
    return df[(df[column] >= Q1 - 1.5 * IQR) & (df[column] <= Q3 + 1.5 * IQR)]

df = remove_outliers_iqr(df, "latency_1080Ti")
df = remove_outliers_iqr(df, "latency_A6000")

summary = []

for expert in df["layer_expert"].unique():
    layer_type = expert.split("_")[0]
    for gpu_col, gpu_name in [("latency_1080Ti", "1080Ti"), ("latency_A6000", "A6000")]:
        sub_df = df[df["layer_expert"] == expert].copy()
        if len(sub_df) < 5:
            print(f"âš ï¸ {expert} ({gpu_name}) ìƒ˜í”Œ ë¶€ì¡±ìœ¼ë¡œ ìŠ¤í‚µ")
            continue

        sub_df["latency_log10"] = np.log10(sub_df[gpu_col])
        scaler = MinMaxScaler()
        y_scaled = scaler.fit_transform(sub_df[["latency_log10"]])

        X = sub_df[["token_count_log"]].values
        y = y_scaled.ravel()
        sample_count = len(sub_df)
        print(f"ğŸ” {expert} ({gpu_name}) ìƒ˜í”Œ ê°œìˆ˜: {sample_count}")

        # ğŸ”½ ëª¨ë¸ ì„ íƒ ë¡œì§
        if sample_count < 500:
            pipeline = Pipeline([
                ('poly', PolynomialFeatures(include_bias=False)),
                ('ridge', Ridge())
            ])

            # í•˜ì´í¼íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ì„¤ì •
            param_grid = {
                'poly__degree': [2, 3],        # ë‹¤í•­ì‹ ì°¨ìˆ˜
                'ridge__alpha': [0.1, 1.0, 10] # Ridge ì •ê·œí™” ê³„ìˆ˜
            }

            # GridSearchCV ì ìš©
            grid = GridSearchCV(
                pipeline,
                param_grid,
                scoring='r2',
                cv=3,
                n_jobs=-1,
                verbose=1
            )

            grid.fit(X, y)
            model = grid.best_estimator_
            model_type = f"Polynomial Ridge (GridSearch)"
        else:
            # SVRë¡œ ê²½í–¥ì„±ë§Œ ë¶€ë“œëŸ½ê²Œ ì¶”ì •
            param_grid = {
                'C': [1, 10, 100],
                'epsilon': [0.001, 0.01, 0.1],
                'gamma': ['scale', 'auto']
            }
            model = SVR(kernel='rbf')
            grid_search = GridSearchCV(model, param_grid, cv=3, scoring='r2', n_jobs=-1)
            grid_search.fit(X, y)
            model = grid_search.best_estimator_
            model_type = f"SVR (GridSearch)"
            model.fit(X, y)
        
        # if sample_count >= 4000:
        #     model = GradientBoostingRegressor(
        #                 n_estimators=200,        # ë” ë§ì€ íŠ¸ë¦¬ â†’ ë¶€ë“œëŸ¬ì›€ ì¦ê°€
        #                 learning_rate=0.03,      # ë‚®ì€ í•™ìŠµë¥  â†’ ëœ íŠ
        #                 max_depth=3,             # ë‚®ì€ ê¹Šì´ â†’ ê³¼ì í•© ë°©ì§€
        #                 subsample=0.7,           # ë¶€ë¶„ ë°ì´í„° ì‚¬ìš© â†’ ë” ì¼ë°˜í™”
        #                 random_state=42
        #             )
        # elif sample_count >= 1000:
        #     model = HistGradientBoostingRegressor(
        #                 max_iter=200,
        #                 max_depth=3,
        #                 learning_rate=0.03,
        #                 l2_regularization=1.0,
        #                 early_stopping=False,
        #                 random_state=42
        #             )
        # else:
        #     model = Ridge(alpha=1.0)

        y_pred = model.predict(X)
        mse = mean_squared_error(y, y_pred)
        r2 = r2_score(y, y_pred)

        # ëª¨ë¸ ë° ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥
        model_dir = f"{layer_type}/{gpu_name}"
        joblib.dump(model, f"{model_dir}/{expert}_model.joblib")
        joblib.dump(scaler, f"{model_dir}/{expert}_scaler.joblib")

        # ğŸ“ˆ ì‹œê°í™”
        token_range = np.arange(1, 513, 10)
        token_log = np.log1p(token_range).reshape(-1, 1)
        pred_scaled = model.predict(token_log)
        pred_log10 = scaler.inverse_transform(pred_scaled.reshape(-1, 1)).flatten()
        pred_latency = np.power(10, pred_log10)

        plt.figure(figsize=(14, 6))
        sns.boxplot(data=df, x="layer_expert", y="token_count", showfliers=False)
        plt.xticks(rotation=90)
        plt.title("Token Count Distribution per Expert")
        plt.xlabel("Layer Expert")
        plt.ylabel("Token Count")
        plt.tight_layout()
        plt.savefig("results/token_distribution_boxplot.png")
        plt.close()

        plt.figure(figsize=(6, 4))
        plt.plot(token_range, pred_latency, label=f"{expert}", color="blue")
        plt.xlabel("Token Count")
        plt.ylabel("Predicted Latency (ms)")
        plt.title(f"{expert} on {gpu_name}")
        plt.grid(True)
        plt.legend()
        plt.tight_layout()
        plt.savefig(f"results/{layer_type}/{gpu_name}/{expert}_curve.png")
        plt.close()

        summary.append({
            "layer_type": layer_type,
            "layer_expert": expert,
            "gpu": gpu_name,
            "samples": sample_count,
            "model_type": model_type,
            "mse": mse,
            "r2": r2
        })

# ğŸ“„ summary ì €ì¥
pd.DataFrame(summary).to_csv("results/training_summary_adaptive.csv", index=False)
print("âœ… ì „ì²´ ëª¨ë¸ í•™ìŠµ ë° ì €ì¥ ì™„ë£Œ")